> [!NOTE]
>
> 本自README的训练和测试GPU环境如下：
>
> NVIDIA RTX 4070Ti：16GB显存
>
> NVIDIA RTX 3060（笔记本电脑）：6GB显存
>
> NVIDIA RTX 2080Ti：11GB显存
>
> NVIDIA RTX 6000（×2）：22GB显存（总计44GB，分布式训练）
>
> **上述GPU均可正常训练**。



### 1. 扩散模型训练

#### 开始你的第一个训练（以cifar10为例，模式单卡）

1. **导入数据集** 

   首先，将数据集上传至目标文件夹`datasets`中[**[issue]**](https://github.com/chairc/Integrated-Design-Diffusion-Model/issues/9#issuecomment-1882902085)。上传后文件夹格式（例如：cifar10文件夹下存放着所有类别；class0文件夹下存储着class0这个类别的所有图片）如下方列表所示：

   ```yaml
    datasets
    └── cifar10
        ├── class0
        ├── class1
        ├── class2
        ├── class3
        ├── class4
        ├── class5
        ├── class6
        ├── class7
        ├── class8
        └── class9
   ```

   此时你的训练前准备已经完毕。

2. **设置训练参数**

   打开`train.py`文件，修改`if __name__ == "__main__":`中的`parser`参数；

   设置`--conditional`参数为`True`，因为是多类别训练，所以需要开启，单类别可以不开启也可以开启；

   设置`--run_name`参数为你想创建的文件名称，例如`cifar_exp1`；

   设置`--dataset_path`参数为`/你的/本地/或/远程服务器/文件/地址/datasets/cifar10`；

   设置`--result_path`参数为`/你的/本地/或/远程服务器/文件/地址/results`；

   设置更多参数（自定义），如果报`CUDA out of memory`错误，将`--batch_size`、`--num_workers`调小；

   在自定义参数中，你可以设置不同的`--sample`例如`ddpm`或`ddim`，设置不同的训练网络`--network`例如`unet`或`cspdarkunet`。当然激活函数`--act`，优化器`--optim`，混合精度训练`--amp`，学习率方法`--lr_func`等参数也都是可以自定义设置的。

   详细命令可参考**训练参数**。

3. **等待训练过程**

   点击`run`运行后，项目会在`results`文件夹中生成`cifar_exp1`文件夹，该文件夹中会保存训练日志文件、模型训练文件、模型EMA文件、模型优化器文件、训练的所有最后一次保存的文件和评估后生成的图片。

4. **查看结果**

   找到`results/cifar_exp1`文件夹即可查看训练结果。



> [!NOTE]
>
> 下方为多种训练方式、训练详细参数讲解



#### 普通训练

##### 命令训练

1. 以`landscape`数据集为例，将数据集文件放入`datasets`文件夹中，该数据集的总路径如下`/your/path/datasets/landscape`，图片存放在`/your/path/datasets/landscape/images`，数据集图片路径如下`/your/path/datasets/landscape/images/*.jpg`

2. 打开`train.py`文件，找到`--dataset_path`参数，将参数中的路径修改为数据集的总路径，例如`/your/path/datasets/landscape`

3. 设置必要参数，例如`--sample`，`--conditional`，`--run_name`，`--epochs`，`--batch_size`，`--image_size`，`--result_path`等参数，若不设置参数则使用默认设置。我们有两种参数设置方法，其一是直接对`train.py`文件`if __name__ == "__main__":`中的`parser`进行设置（**我们推荐这种方式**）；其二是在控制台在`/your/path/Defect-Diffiusion-Model/iddm/tools`路径下输入以下命令： 
   
   **有条件训练命令**

   ```bash
   python train.py --sample ddpm --conditional --run_name df --epochs 300 --batch_size 16 --image_size 64 --dataset_path /your/dataset/path --result_path /your/save/path
   ```

   **无条件训练命令**

   ```bash
   python train.py --sample ddpm --run_name df --epochs 300 --batch_size 16 --image_size 64 --dataset_path /your/dataset/path --result_path /your/save/path
   ```

4. 等待训练即可

5. 若因异常原因中断训练[**[issue]**](https://github.com/chairc/Integrated-Design-Diffusion-Model/issues/9#issuecomment-1882912391)，我们可以在`train.py`文件，首先设置`--resume`为`True`，其次设置异常中断的迭代编号，再写入该次训练的所在文件夹（run_name），最后运行文件即可。也可以使用如下命令进行恢复： 
   
   **有条件恢复训练命令**

   ```bash
   # 此处为输入--start_epoch参数，使用当前编号权重
   python train.py --resume --start_epoch 10 --sample ddpm --conditional --run_name df --epochs 300 --batch_size 16 --image_size 64 --dataset_path /your/dataset/path --result_path /your/save/path
   ```

   ```bash
   # 此处为不输入--start_epoch参数，默认使用last权重
   python train.py --resume --sample ddpm --conditional --run_name df --epochs 300 --batch_size 16 --image_size 64 --dataset_path /your/dataset/path --result_path /your/save/path
   ```

   **无条件恢复训练命令**

   ```bash
   python train.py --resume --start_epoch 10 --sample ddpm --run_name df --epochs 300 --batch_size 16 --image_size 64 --dataset_path /your/dataset/path --result_path /your/save/path
   ```

   ```bash
   # 此处为不输入--start_epoch参数，默认使用last权重
   python train.py --resume --sample ddpm --run_name df --epochs 300 --batch_size 16 --image_size 64 --dataset_path /your/dataset/path --result_path /your/save/path
   ```

6. 预训练模型在每次大版本[Release](https://github.com/chairc/Integrated-Design-Diffusion-Model/releases)中发布，请留意。预训练模型使用方法如下[**[issue]**](https://github.com/chairc/Integrated-Design-Diffusion-Model/issues/9#issuecomment-1886403967)，首先将对应`network`、`image_size`、`act`等相同参数的模型下到本地任意文件夹下。直接调整`train.py`中`--pretrain`和`--pretrain_path`即可。也可以使用如下命令进行预训练： 
   
   **使用有条件预训练模型训练命令**

   ```bash
   python train.py --pretrain --pretrain_path /your/pretrain/path/model.pt --sample ddpm --conditional --run_name df --epochs 300 --batch_size 16 --image_size 64 --dataset_path /your/dataset/path --result_path /your/save/path
   ```

   **使用无条件预训练模型训练命令**

   ```bash
   python train.py --pretrain --pretrain_path /your/pretrain/path/model.pt --sample ddpm --run_name df --epochs 300 --batch_size 16 --image_size 64 --dataset_path /your/dataset/path --result_path /your/save/path
   ```

7. 潜扩散模型训练时，首先将对应`latent`设置为`True`、`autoencoder_network`设置为本次训练提供编解码功能的变分自编码器模型、`autoencoder_ckpt`设置为当前变分自编码器的权重路径，其余设置与普通扩散模型训练相同。也可以使用如下命令进行潜扩散模型训练： 
   
   **使用有条件潜扩散模型训练命令**

   ```bash
   python train.py --latent --autoencoder_network vae --autoencoder_ckpt /your/path/of/autoencoder/weight.pt --sample ddpm --conditional --run_name ldm --epochs 300 --batch_size 8 --image_size 64 --dataset_path /your/dataset/path --result_path /your/save/path
   ```

   **使用无条件潜扩散模型模型训练命令**

   ```bash
   python train.py --latent --autoencoder_network vae --autoencoder_ckpt /your/path/of/autoencoder/weight.pt --sample ddpm --run_name ldm --epochs 300 --batch_size 8 --image_size 64 --dataset_path /your/dataset/path --result_path /your/save/path
   ```

##### Python脚本训练

```python
from iddm.model.trainers.dm import DMTrainer
from iddm.tools.train import init_train_args

# 方法一
# 初始化参数
args = init_train_args()
# 自定义你的参数，也可以进入init_train_args方法配置
setattr(args, "conditional", True) # True为条件训练，False为非条件训练
setattr(args, "sample", "ddpm") # 采样器
setattr(args, "network", "unet") # 深度学习网络
setattr(args, "epochs", 300) # 迭代次数
setattr(args, "image_size", 64) # 图像大小
setattr(args, "dataset_path", "/你/的/数/据/集/路/径/") # 数据集保存路径
setattr(args, "result_path", "/你/的/保/存/路/径/") # 结果保存路径
setattr(args, "latent", True) # 开启潜在训练
setattr(args, "autoencoder_network", "vae") # VAE训练网络
setattr(args, "autoencoder_ckpt", "/你/的/VAE/模/型/路/径/weight.pt") # VAE权重路径
# ...
# 或者使用args["参数名称"] = "你的设置"
# 开启训练
DMTrainer(args=args).train()

# 方法二
args = init_train_args()
# 输入args，修改指定参数输入
DMTrainer(args=args, dataset_path="/你/的/数/据/集").train()

# 方法三
DMTrainer(
    conditional=True, sample="ddpm", dataset_path="/你/的/数/据/集/路/径/",
    network="unet", epochs=300, image_size=64, result_path="/你/的/保/存/路/径/",
    vis=True, latent=True, autoencoder_network="vae",
    autoencoder_ckpt="/你/的/VAE/模/型/路/径/weight.pt", # 任意参数...
).train()
```



#### 分布式训练

##### 命令训练

1. 基本配置与普通训练相似，值得注意的是开启分布式训练需要设置`--distributed`。为了防止随意设置分布式训练，我们为开启分布式训练设置了几个基本条件，例如`args.distributed`、`torch.cuda.device_count() > 1`和`torch.cuda.is_available()`。

2. 设置必要的参数，例如`--main_gpu`和`--world_size`。`--main_gpu`通常设置为主要GPU，例如做验证、做测试或保存权重，我们仅在单卡中运行即可。而`world_size`的值会与实际使用的GPU数量或分布式节点数量相对应。

3. 我们有两种参数设置方法，其一是直接对`train.py`文件`if __name__ == "__main__":`中的`parser`进行设置；其二是在控制台在`/your/path/Defect-Diffiusion-Model/iddm/tools`路径下输入以下命令： 

   **有条件训练命令**

   ```bash
   python train.py --sample ddpm --conditional --run_name df --epochs 300 --batch_size 16 --image_size 64  --dataset_path /your/dataset/path --result_path /your/save/path --distributed --main_gpu 0 --world_size 2
   ```

   **无条件训练命令**

   ```bash
   python train.py --sample ddpm --run_name df --epochs 300 --batch_size 16 --image_size 64 --dataset_path /your/dataset/path --result_path /your/save/path --distributed --main_gpu 0 --world_size 2
   ```

4. 等待训练即可，中断恢复同基本训练一致。

![IDDM分布式训练过程](../../assets/IDDM_training.png)

##### Python脚本训练

```python
import torch
from torch import multiprocessing as mp
from iddm.model.trainers.dm import DMTrainer
from iddm.tools.train import init_train_args

# 方法一
# 初始化参数
args = init_train_args()
gpus = torch.cuda.device_count()
# 自定义你的参数，也可以进入init_train_args方法配置
setattr(args, "distributed", True)  # 开启分布式训练
setattr(args, "world_size", 2)  # 训练结点个数
setattr(args, "conditional", True) # True为条件训练，False为非条件训练
setattr(args, "sample", "ddpm") # 采样器
setattr(args, "network", "unet") # 深度学习网络
setattr(args, "epochs", 300) # 迭代次数
setattr(args, "image_size", 64) # 图像大小
setattr(args, "dataset_path", "/你/的/数/据/集/路/径/") # 数据集保存路径
setattr(args, "result_path", "/你/的/保/存/路/径/") # 结果保存路径
setattr(args, "vis", True) # 开启可视化
setattr(args, "latent", True) # 开启潜在训练
setattr(args, "autoencoder_network", "vae") # VAE训练网络
setattr(args, "autoencoder_ckpt", "/你/的/VAE/模/型/路/径/weight.pt") # VAE权重路径
# ...
# 或者使用args["参数名称"] = "你的设置"
# 开启训练
mp.spawn(DMTrainer(args=args).train, nprocs=gpus)

# 方法二
args = init_train_args()
# 输入args，修改指定参数输入
mp.spawn(DMTrainer(args=args, dataset_path="/你/的/数/据/集").train, nprocs=gpus)

# 方法三
mp.spawn(DMTrainer(
    conditional=True, sample="ddpm", dataset_path="/你/的/数/据/集/路/径/",
    network="unet", epochs=300, image_size=64, result_path="/你/的/保/存/路/径/",
    vis=True, latent=True, autoencoder_network="vae",
    autoencoder_ckpt="/你/的/VAE/模/型/路/径/weight.pt", # 任意参数...
).train, nprocs=gpus)
```



#### 训练参数

**参数讲解**

> [!WARNING]
>
> `--num_classes`在**1.1.4版本**后的模型可不用设置

| **参数名称**                 | 条件参数 | 参数使用方法                     | 参数类型 | 参数解释                                                     |
| ---------------------------- | :------: | -------------------------------- | :------: | ------------------------------------------------------------ |
| --seed                       |          | 初始化种子                       |   int    | 设置初始化种子，可复现网络生成的图片                         |
| --conditional                |          | 开启条件训练                     |   bool   | 若开启可修改自定义配置，例如修改类别、classifier-free guidance插值权重 |
| --latent                     |          | 是否开启潜扩散训练               |   bool   | 若开启模型将进行潜扩散训练                                   |
| --sample                     |          | 采样方式                         |   str    | 设置采样器类别，当前支持ddpm，ddim                           |
| --network                    |          | 训练网络                         |   str    | 设置训练网络，当前支持UNet，CSPDarkUNet                      |
| --run_name                   |          | 文件名称                         |   str    | 初始化模型的文件名称，用于设置保存信息                       |
| --epochs                     |          | 总迭代次数                       |   int    | 训练总迭代次数                                               |
| --batch_size                 |          | 训练批次                         |   int    | 训练批次大小                                                 |
| --num_workers                |          | 加载进程数量                     |   int    | 用于数据加载的子进程数量，大量占用CPU和内存，但可以加快训练速度 |
| --image_size                 |          | 输入图像大小                     |   int    | 输入图像大小，自适应输入输出尺寸                             |
| --dataset_path               |          | 数据集路径                       |   str    | 有条件数据集，例如cifar10，每个类别一个文件夹，路径为主文件夹；无条件数据集，所有图放在一个文件夹，路径为图片文件夹 |
| --amp                        |          | 混合精度训练                     |   bool   | 开启混合精度训练，有效减少显存使用，但无法保证训练精度和训练结果 |
| --optim                      |          | 优化器                           |   str    | 优化器选择，目前支持adam和adamw                              |
| --loss                       |          | 损失函数                         |   str    | 损失函数选择，目前支持MSELoss、L1Loss、HuberLoss和moothL1Loss |
| --act                        |          | 激活函数                         |   str    | 激活函数选择，目前支持gelu、silu、relu、relu6和lrelu         |
| --lr                         |          | 学习率                           |  float   | 初始化学习率                                                 |
| --lr_func                    |          | 学习率方法                       |   str    | 设置学习率方法，当前支持linear、cosine和warmup_cosine        |
| --result_path                |          | 保存路径                         |   str    | 保存路径                                                     |
| --save_model_interval        |          | 是否在训练中储存                 |   bool   | 是否在训练中储存，根据可视化生成样本信息筛选模型，如果为False，则只保存最后一个模型 |
| --save_model_interval_epochs |          | 保存模型周期                     |   int    | 保存模型间隔并每 X 周期保存一个模型                          |
| --start_model_interval       |          | 设置开始每次训练存储编号         |   int    | 设置开始每次训练存储的epoch编号，该设置可节约磁盘空间，若不设置默认-1，若设置则从第epoch时开始保存每次训练pt文件，需要与--save_model_interval同时开启 |
| --vis                        |          | 可视化数据集信息                 |   bool   | 打开可视化数据集信息，根据可视化生成样本信息筛选模型         |
| --num_vis                    |          | 生成的可视化图像数量             |   int    | 生成的可视化图像数量。如果不填写，则默认生成图片个数为数据集类别的个数 |
| --image_format               |          | 生成图片格式                     |   str    | 在训练中生成图片格式，默认为png                              |
| --noise_schedule             |          | 加噪方法                         |   str    | 该方法是模型噪声添加方法                                     |
| --resume                     |          | 中断恢复训练                     |   bool   | 恢复训练将设置为“True”。注意：设置异常中断的epoch编号若在--start_model_interval参数条件外，则不生效。例如开始保存模型时间为100，中断编号为50，由于我们没有保存模型，所以无法设置任意加载epoch点。每次训练我们都会保存xxx_last.pt文件，所以我们需要使用最后一次保存的模型进行中断训练 |
| --start_epoch                |          | 中断迭代编号                     |   int    | 设置异常中断的epoch编号，模型会自动加载当前编号的检查点      |
| --pretrain                   |          | 预训练模型训练                   |   bool   | 设置是否启用加载预训练模型训练                               |
| --pretrain_path              |          | 预训练模型路径                   |   str    | 预训练模型加载地址                                           |
| --use_gpu                    |          | 设置运行指定的GPU                |   int    | 一般训练中设置指定的运行GPU，输入为GPU的编号                 |
| --distributed                |          | 分布式训练                       |   bool   | 开启分布式训练                                               |
| --main_gpu                   |          | 分布式训练主显卡                 |   int    | 设置分布式中主显卡                                           |
| --world_size                 |          | 分布式训练的节点等级             |   int    | 分布式训练的节点等级， world_size的值会与实际使用的GPU数量或分布式节点数量相对应 |
| --num_classes                |    是    | 类别个数                         |   int    | 类别个数，用于区分类别（**1.1.4版本后的模型可不用设置**）    |
| --cfg_scale                  |    是    | classifier-free guidance插值权重 |   int    | classifier-free guidance插值权重，用户更好生成模型效果       |
| --autoencoder_network        |          | 变分自编码器模型                 |   str    | 变分自编码器模型，进行编解码功能                             |
| --autoencoder_ckpt           |          | 变分自编码器权重路径             |   str    | 变分自编码器权重路径                                         |



### 2. 变分自编码器模型训练

#### 训练准备

1. **导入数据集** 

   首先，将数据集上传至目标文件夹`datasets`中。上传后文件夹格式（例如：neu-det文件夹下存放着train和val；images文件夹下存储着所有训练图片）如下方列表所示：

   ```yaml
   datasets
   └── neu-det
       │
       ├── train
       │   └── images
       │       ├── image_1.jpg
       │       ├── image_2.jpg
       │       └── ...
       │
       └── val
           └── images
               ├── image_1.jpg
               ├── image_2.jpg
               └── ...
   ```

   此时你的训练前准备已经完毕。

2. **设置训练参数**

   打开`/iddm/autoencoder/train.py`文件，修改`if __name__ == "__main__":`中的`parser`参数；

   设置`--run_name`参数为你想创建的文件名称，例如`neudet_autoencoder`；

   设置`--images_size`参数为你图像输入的尺寸（建议默认），例如`512`；

   设置`--dataset_path`参数为`/你的/本地/或/远程服务器/文件/地址/datasets/neudet`；

   设置`--result_path`参数为`/你的/本地/或/远程服务器/文件/地址/results`；

   设置更多参数（自定义），如果报`CUDA out of memory`错误，将`--batch_size`、`--num_workers`调小；

   在自定义参数中，设置不同的训练网络`--network`例如`vae`，激活函数`--act`，优化器`--optim`，混合精度训练`--amp`，学习率方法`--lr_func`等参数也都是可以自定义设置的。

   详细命令可参考**训练参数**。

3. **等待训练过程**

   点击`run`运行后，项目会在`results`文件夹中生成`neudet_autoencoder`文件夹，该文件夹中会保存训练日志文件、模型训练文件、模型EMA文件、模型优化器文件、训练的所有最后一次保存的文件和评估后生成的图片。

4. **查看结果**

   找到`results/neudet_autoencoder`文件夹即可查看训练结果。



#### 普通训练

> [!NOTE]
>
> 详细训练请参考：**1. 扩散模型训练 - 普通训练**
>



#### 分布式训练

> [!NOTE]
>
> 详细训练请参考：**1. 扩散模型训练 - 分布式训练**



#### 训练参数

**参数讲解**

| **参数名称**                 | 参数使用方法             | 参数类型 | 参数解释                                                     |
| ---------------------------- | ------------------------ | :------: | ------------------------------------------------------------ |
| --seed                       | 初始化种子               |   int    | 设置初始化种子，可复现网络生成的图片                         |
| --network                    | 训练网络                 |   str    | 设置训练网络，当前支持vae                                    |
| --run_name                   | 文件名称                 |   str    | 初始化模型的文件名称，用于设置保存信息                       |
| --epochs                     | 总迭代次数               |   int    | 训练总迭代次数                                               |
| --batch_size                 | 训练批次                 |   int    | 训练批次大小                                                 |
| --num_workers                | 加载进程数量             |   int    | 用于数据加载的子进程数量，大量占用CPU和内存，但可以加快训练速度 |
| --image_size                 | 输入图像大小             |   int    | 输入图像大小，自适应输入输出尺寸                             |
| --latent_channels            | 潜扩散通道               |   int    | VAE编解码器的通道，默认为8                                   |
| --train_dataset_path         | 训练数据集路径           |   str    | 训练数据集                                                   |
| --val_dataset_path           | 验证数据集路径           |   str    | 验证数据集                                                   |
| --amp                        | 混合精度训练             |   bool   | 开启混合精度训练，有效减少显存使用，但无法保证训练精度和训练结果 |
| --optim                      | 优化器                   |   str    | 优化器选择，目前支持sdg、adam和adamw                         |
| --loss                       | 损失函数                 |   str    | 损失函数选择，目前支持MSEKLLoss                              |
| --act                        | 激活函数                 |   str    | 激活函数选择，目前支持gelu、silu、relu、relu6和lrelu         |
| --lr                         | 学习率                   |  float   | 初始化学习率                                                 |
| --lr_func                    | 学习率方法               |   str    | 设置学习率方法，当前支持linear、cosine和warmup_cosine        |
| --result_path                | 保存路径                 |   str    | 保存路径                                                     |
| --save_model_interval        | 是否在训练中储存         |   bool   | 是否在训练中储存，根据可视化生成样本信息筛选模型，如果为False，则只保存最后一个模型 |
| --save_model_interval_epochs | 保存模型周期             |   int    | 保存模型间隔并每 X 周期保存一个模型                          |
| --start_model_interval       | 设置开始每次训练存储编号 |   int    | 设置开始每次训练存储的epoch编号，该设置可节约磁盘空间，若不设置默认-1，若设置则从第epoch时开始保存每次训练pt文件，需要与--save_model_interval同时开启 |
| --image_format               | 生成图片格式             |   str    | 在训练中生成图片格式，默认为png                              |
| --resume                     | 中断恢复训练             |   bool   | 恢复训练将设置为“True”。注意：设置异常中断的epoch编号若在--start_model_interval参数条件外，则不生效。例如开始保存模型时间为100，中断编号为50，由于我们没有保存模型，所以无法设置任意加载epoch点。每次训练我们都会保存xxx_last.pt文件，所以我们需要使用最后一次保存的模型进行中断训练 |
| --start_epoch                | 中断迭代编号             |   int    | 设置异常中断的epoch编号，模型会自动加载当前编号的检查点      |
| --pretrain                   | 预训练模型训练           |   bool   | 设置是否启用加载预训练模型训练                               |
| --pretrain_path              | 预训练模型路径           |   str    | 预训练模型加载地址                                           |
| --use_gpu                    | 设置运行指定的GPU        |   int    | 一般训练中设置指定的运行GPU，输入为GPU的编号                 |
| --distributed                | 分布式训练               |   bool   | 开启分布式训练                                               |
| --main_gpu                   | 分布式训练主显卡         |   int    | 设置分布式中主显卡                                           |
| --world_size                 | 分布式训练的节点等级     |   int    | 分布式训练的节点等级， world_size的值会与实际使用的GPU数量或分布式节点数量相对应 |